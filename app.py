"""
Streamlit IDS App - CatBoost + LOF
Clean version with working random sample generation
"""

from __future__ import annotations
import streamlit as st
import pickle
import json
import numpy as np
import pandas as pd
import os

# Page config
st.set_page_config(
    page_title="IDS - Inference Dashboard",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Dark theme CSS
st.markdown('''
    <style>
    .main {background-color: #000000; color: #ffffff;}
    [data-testid="stSidebar"] {background-color: #1a1a1a;}
    .stMetric {background-color: #1a1a1a; padding: 10px; border-radius: 5px; border: 1px solid #333333;}
    h1, h2, h3, h4, h5, h6 {color: #ffffff !important;}
    </style>
''', unsafe_allow_html=True)

@st.cache_resource
def load_models():
    """Load pre-trained models with Google Drive support"""
    
    # Check if file exists locally
    if os.path.exists('trained_models.pkl'):
        try:
            with open('trained_models.pkl', 'rb') as f:
                models = pickle.load(f)
            st.sidebar.success("‚úÖ Models loaded")
            return models
        except Exception as e:
            st.error(f"‚ùå Error loading: {str(e)}")
            if st.button("üóëÔ∏è Delete and re-upload"):
                os.remove('trained_models.pkl')
                st.rerun()
    
    # Show upload interface if model not found
    st.error("### ‚ùå Model file not found!")
    st.markdown("---")
    
    # Tabs for different options
    tab1, tab2 = st.tabs(["üîó Google Drive Link", "üìã Instructions"])
    
    with tab1:
        st.markdown("### üîó Download from Google Drive")
        st.markdown("""
        **Steps to get your link:**
        1. Upload `trained_models.pkl` to Google Drive
        2. Right-click ‚Üí Share ‚Üí "Anyone with the link"
        3. Copy the link
        4. Paste below and click Download
        """)
        
        st.markdown("---")
        
        gdrive_link = st.text_input(
            "Google Drive Link:",
            placeholder="https://drive.google.com/file/d/YOUR_FILE_ID/view?usp=sharing",
            help="Paste your Google Drive shareable link here"
        )
        
        if st.button("üì• Download from Google Drive", type="primary"):
            if not gdrive_link:
                st.error("‚ùå Please enter a Google Drive link")
            else:
                try:
                    # Extract file ID
                    if '/d/' in gdrive_link:
                        file_id = gdrive_link.split('/d/')[1].split('/')[0]
                    elif 'id=' in gdrive_link:
                        file_id = gdrive_link.split('id=')[1].split('&')[0]
                    else:
                        file_id = gdrive_link
                    
                    st.info(f"File ID: {file_id}")
                    
                    # Download using requests (no gdown needed)
                    import requests
                    
                    def download_file_from_google_drive(file_id, destination):
                        URL = "https://docs.google.com/uc?export=download"
                        
                        session = requests.Session()
                        response = session.get(URL, params={'id': file_id}, stream=True)
                        
                        # Check for download warning
                        token = None
                        for key, value in response.cookies.items():
                            if key.startswith('download_warning'):
                                token = value
                        
                        if token:
                            params = {'id': file_id, 'confirm': token}
                            response = session.get(URL, params=params, stream=True)
                        
                        # Save file
                        CHUNK_SIZE = 32768
                        with open(destination, "wb") as f:
                            for chunk in response.iter_content(CHUNK_SIZE):
                                if chunk:
                                    f.write(chunk)
                    
                    with st.spinner("üì• Downloading from Google Drive (300MB)... This may take 1-2 minutes"):
                        download_file_from_google_drive(file_id, 'trained_models.pkl')
                    
                    # Check if downloaded
                    if os.path.exists('trained_models.pkl'):
                        file_size = os.path.getsize('trained_models.pkl') / 1024 / 1024
                        if file_size > 1:  # At least 1MB
                            st.success(f"‚úÖ Downloaded {file_size:.1f} MB!")
                            st.info("üîÑ Reloading page...")
                            st.rerun()
                        else:
                            st.error("‚ùå Download failed - file too small")
                            os.remove('trained_models.pkl')
                    else:
                        st.error("‚ùå Download failed")
                        
                except Exception as e:
                    st.error(f"‚ùå Download error: {str(e)}")
                    st.info("**Troubleshooting:**")
                    st.markdown("""
                    - Make sure the link is set to "Anyone with the link"
                    - Try copying the link again
                    - Check if file ID is correct
                    """)
        
        st.markdown("---")
        st.markdown("**Example link format:**")
        st.code("https://drive.google.com/file/d/1AbCdEfGhIjKlMnOpQrStUvWxYz/view?usp=sharing")
    
    with tab2:
        st.markdown("""
        ### üìã How to Setup Google Drive Link
        
        **Step 1: Upload to Google Drive**
        ```bash
        # After training locally:
        python train_catboost_lof.py
        # Creates trained_models.pkl (300MB)
        ```
        
        1. Go to [drive.google.com](https://drive.google.com)
        2. Click "New" ‚Üí "File upload"
        3. Select `trained_models.pkl`
        4. Wait for upload (2-3 minutes)
        
        **Step 2: Make Shareable**
        1. Right-click on the uploaded file
        2. Click "Share"
        3. Change to **"Anyone with the link"**
        4. Set permission to **"Viewer"**
        5. Click "Copy link"
        
        **Step 3: Use in App**
        1. Go to "üîó Google Drive Link" tab
        2. Paste the link
        3. Click "üì• Download from Google Drive"
        4. Wait 1-2 minutes
        5. App reloads with models!
        
        ---
        
        ### ‚ö†Ô∏è Important Notes
        
        - File must be set to "Anyone with the link"
        - Download takes 1-2 minutes for 300MB
        - Models are cached after first download
        - Use GitHub for small files (<100MB)
        """)
    
    st.stop()

@st.cache_data
def load_metrics():
    """Load metrics"""
    if not os.path.exists('metrics.json'):
        return None
    try:
        with open('metrics.json', 'r') as f:
            return json.load(f)
    except:
        return None

@st.cache_data
def load_sample_predictions():
    """Load sample predictions"""
    if not os.path.exists('sample_predictions.json'):
        return None
    try:
        with open('sample_predictions.json', 'r') as f:
            return json.load(f)
    except:
        return None

def generate_realistic_sample(models):
    """
    Generate sample from actual test data distribution
    This ensures LOF recognizes the patterns
    """
    # Try to load actual test samples first
    try:
        if os.path.exists('sample_predictions.json'):
            with open('sample_predictions.json', 'r') as f:
                sample_data = json.load(f)
            
            # Check if we have feature data
            if 'X_test_samples' in sample_data and len(sample_data['X_test_samples']) > 0:
                # Get random sample from actual test data
                idx = np.random.randint(0, len(sample_data['X_test_samples']))
                sample = sample_data['X_test_samples'][idx]
                is_benign = sample_data['y_true'][idx] == 0
                return sample, is_benign
    except:
        pass
    
    # Fallback: generate synthetic sample
    # Use VERY small variations to avoid being flagged as outlier
    n_features = len(models['feature_names'])
    is_benign = np.random.rand() > 0.5
    
    sample = []
    for _ in range(n_features):
        if is_benign:
            # Benign: tiny variations (within 1 std dev)
            value = np.random.normal(0, 0.3)
        else:
            # Attack: moderate outliers (not too extreme)
            if np.random.rand() > 0.6:
                value = np.random.choice([np.random.uniform(2, 4), np.random.uniform(-4, -2)])
            else:
                value = np.random.normal(0, 0.5)
        sample.append(float(value))
    
    return sample, is_benign

def predict_single_sample(models, features, pre_scaled=False):
    """Make prediction - CatBoost + LOF"""
    # Scale features only if not already scaled
    if pre_scaled:
        features_scaled = np.array(features).reshape(1, -1)
    else:
        features_scaled = models['scaler'].transform([features])
    
    # CatBoost
    catboost_proba = models['catboost_model'].predict_proba(features_scaled)[0, 1]
    catboost_pred = 1 if catboost_proba >= models['catboost_threshold'] else 0
    
    # LOF
    lof_decision = models['lof_model'].predict(features_scaled)[0]
    lof_pred = 1 if lof_decision == -1 else 0
    
    # LOF probability - improved calculation
    # score_samples returns: negative values = outliers (attacks)
    lof_score = models['lof_model'].score_samples(features_scaled)[0]
    
    # More aggressive scaling to get varied probabilities
    # Adjust multiplier based on typical score range
    if lof_score < -2:
        # Very negative = definitely attack
        lof_proba = 0.95
    elif lof_score < -1:
        # Moderately negative = likely attack
        lof_proba = 0.70 + (abs(lof_score) - 1) * 0.25
    elif lof_score < 0:
        # Slightly negative = maybe attack
        lof_proba = 0.50 + abs(lof_score) * 0.20
    elif lof_score < 1:
        # Slightly positive = probably benign
        lof_proba = 0.50 - lof_score * 0.20
    elif lof_score < 2:
        # Moderately positive = likely benign
        lof_proba = 0.30 - (lof_score - 1) * 0.20
    else:
        # Very positive = definitely benign
        lof_proba = 0.05
    
    lof_proba = np.clip(lof_proba, 0.01, 0.99)
    
    # Voting
    voting_pred = max(catboost_pred, lof_pred)
    voting_proba = max(catboost_proba, lof_proba)
    
    return {
        'catboost_pred': catboost_pred,
        'catboost_proba': catboost_proba,
        'lof_pred': lof_pred,
        'lof_proba': lof_proba,
        'lof_score': lof_score,  # For debugging
        'voting_pred': voting_pred,
        'voting_proba': voting_proba
    }

# Main app
st.title("üõ°Ô∏è IDS Inference Dashboard")
st.markdown("**CatBoost + LOF Hybrid Model**")
st.caption("Fast inference ‚Ä¢ Google Drive support")
st.markdown("---")

# Load everything
models = load_models()
metrics = load_metrics()
sample_preds = load_sample_predictions()

# Sidebar
st.sidebar.header("‚öôÔ∏è Mode Selection")
mode = st.sidebar.radio(
    "Choose Mode:",
    ["üìä View Metrics", "üéØ Live Prediction", "üìã Sample Predictions"]
)

st.sidebar.markdown("---")
st.sidebar.subheader("üìà Model Info")
if metrics:
    st.sidebar.info(f"**Trained:** {metrics.get('training_date', 'Unknown')[:10]}")
    st.sidebar.info(f"**Samples:** {metrics['dataset_info']['total_samples']:,}")
    st.sidebar.info(f"**Features:** {metrics['dataset_info']['features']}")

if os.path.exists('trained_models.pkl'):
    file_size = os.path.getsize('trained_models.pkl') / 1024 / 1024
    st.sidebar.success(f"üì¶ Model: {file_size:.1f} MB")

# MODE 1: View Metrics
if mode == "üìä View Metrics":
    st.header("üìä Model Performance Metrics")
    
    if metrics is None:
        st.error("Metrics not found!")
        st.stop()
    
    results = metrics['results']
    
    col1, col2, col3, col4, col5 = st.columns(5)
    col1.metric("Accuracy", f"{results['accuracy']:.3f}")
    col2.metric("Precision", f"{results['precision']:.3f}")
    col3.metric("Recall", f"{results['recall']:.3f}")
    col4.metric("F1-Score", f"{results['f1_score']:.3f}")
    col5.metric("ROC-AUC", f"{results.get('roc_auc', 0):.3f}")
    
    st.markdown("---")
    
    col_a, col_b = st.columns(2)
    
    with col_a:
        st.subheader("Confusion Matrix")
        st.metric("True Positives", f"{results['true_positives']:,}")
        st.metric("True Negatives", f"{results['true_negatives']:,}")
        st.metric("False Positives", f"{results['false_positives']:,}")
        st.metric("False Negatives", f"{results['false_negatives']:,}")
    
    with col_b:
        st.subheader("Additional Metrics")
        st.metric("FPR", f"{results['fpr']:.4f}")
        st.metric("FNR", f"{results['fnr']:.4f}")
        st.metric("Training Time", f"{results['training_time']:.2f}s")

# MODE 2: Live Prediction
elif mode == "üéØ Live Prediction":
    st.header("üéØ Live Attack Prediction")
    st.markdown("Enter network flow features to predict if traffic is benign or attack")
    
    st.markdown("---")
    
    feature_names = models['feature_names']
    n_features = len(feature_names)
    
    # Random sample button
    if st.button("üé≤ Generate Random Sample"):
        # Generate realistic sample IN SCALED SPACE
        random_values, expected_class = generate_realistic_sample(models)
        st.session_state.random_values = random_values
        st.session_state.expected_class = expected_class
        st.session_state.random_sample = True
        st.session_state.values_are_scaled = True  # Mark as already scaled
        st.rerun()
    
    # Show hint if random sample was generated
    if st.session_state.get('random_sample', False):
        expected = "üü¢ Benign" if st.session_state.get('expected_class', False) else "üî¥ Attack"
        st.info(f"üí° Generated sample with {expected}-like pattern (values are in scaled space)")
    
    
    st.markdown("**Quick Input (Top 10 Features):**")
    
    input_values = []
    col1, col2 = st.columns(2)
    
    # Show first 10 features
    for i, feature in enumerate(feature_names[:10]):
        if i % 2 == 0:
            with col1:
                # Use pre-generated random values if available
                if st.session_state.get('random_sample', False) and 'random_values' in st.session_state:
                    default = st.session_state.random_values[i]
                else:
                    default = 0.0
                
                val = st.number_input(
                    feature, 
                    value=float(default), 
                    format="%.4f", 
                    key=f"feat_{i}"
                )
                input_values.append(val)
        else:
            with col2:
                # Use pre-generated random values if available
                if st.session_state.get('random_sample', False) and 'random_values' in st.session_state:
                    default = st.session_state.random_values[i]
                else:
                    default = 0.0
                
                val = st.number_input(
                    feature, 
                    value=float(default), 
                    format="%.4f", 
                    key=f"feat_{i}"
                )
                input_values.append(val)
    
    # Fill remaining features (hidden) from pre-generated values
    if st.session_state.get('random_sample', False) and 'random_values' in st.session_state:
        input_values.extend(st.session_state.random_values[10:])
    else:
        input_values.extend([0.0 for _ in range(n_features - 10)])
    
    st.markdown("---")
    
    # Predict button
    if st.button("üöÄ Predict", type="primary"):
        # Check if values are already scaled
        values_are_scaled = st.session_state.get('values_are_scaled', False)
        
        with st.spinner("Making prediction..."):
            if values_are_scaled:
                # Values are already in scaled space, use directly
                prediction = predict_single_sample(models, input_values, pre_scaled=True)
            else:
                # Values need scaling (manual input)
                prediction = predict_single_sample(models, input_values, pre_scaled=False)
        
        st.success("‚úÖ Prediction Complete!")
        
        # Show results
        st.markdown("---")
        st.subheader("üéØ Prediction Results")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("### CatBoost")
            result = "üî¥ **ATTACK**" if prediction['catboost_pred'] == 1 else "üü¢ **BENIGN**"
            st.markdown(result)
            st.metric("Confidence", f"{prediction['catboost_proba']:.2%}")
        
        with col2:
            st.markdown("### LOF")
            result = "üî¥ **ATTACK**" if prediction['lof_pred'] == 1 else "üü¢ **BENIGN**"
            st.markdown(result)
            st.metric("Confidence", f"{prediction['lof_proba']:.2%}")
        
        with col3:
            st.markdown("### üéñÔ∏è **Voting Ensemble**")
            result = "üî¥ **ATTACK**" if prediction['voting_pred'] == 1 else "üü¢ **BENIGN**"
            st.markdown(f"## {result}")
            st.metric("Confidence", f"{prediction['voting_proba']:.2%}")
        
        # Debug info
        with st.expander("üîç Debug Info"):
            st.json({
                'CatBoost': {
                    'probability': f"{prediction['catboost_proba']:.4f}",
                    'prediction': 'ATTACK' if prediction['catboost_pred'] == 1 else 'BENIGN',
                    'threshold': models['catboost_threshold']
                },
                'LOF': {
                    'raw_score': f"{prediction.get('lof_score', 0):.4f}",
                    'probability': f"{prediction['lof_proba']:.4f}",
                    'prediction': 'ATTACK' if prediction['lof_pred'] == 1 else 'BENIGN',
                    'note': 'Negative scores = outliers/attacks'
                },
                'Voting': {
                    'strategy': 'OR logic (max of both)',
                    'final': 'ATTACK' if prediction['voting_pred'] == 1 else 'BENIGN'
                }
            })
        
        # Clear random sample flags
        st.session_state.random_sample = False
        st.session_state.values_are_scaled = False

# MODE 3: Sample Predictions
elif mode == "üìã Sample Predictions":
    st.header("üìã Sample Test Predictions")
    
    if sample_preds is None:
        st.error("Sample predictions not found!")
        st.stop()
    
    df = pd.DataFrame({
        'True Label': ['Attack' if y == 1 else 'Benign' for y in sample_preds['y_true']],
        'CatBoost': ['Attack' if y == 1 else 'Benign' for y in sample_preds['y_pred_catboost']],
        'LOF': ['Attack' if y == 1 else 'Benign' for y in sample_preds['y_pred_lof']],
        'Voting': ['Attack' if y == 1 else 'Benign' for y in sample_preds['y_pred_voting']],
        'CatBoost Prob': sample_preds['proba_catboost'],
        'LOF Prob': sample_preds['proba_lof'],
        'Voting Prob': sample_preds['proba_voting']
    })
    
    col1, col2 = st.columns(2)
    with col1:
        filter_option = st.selectbox(
            "Filter", 
            ["All", "Correct Predictions", "Incorrect Predictions", "Attacks Only", "Benign Only"]
        )
    with col2:
        n_rows = st.slider("Rows to display", 10, 100, 50)
    
    y_true = np.array(sample_preds['y_true'])
    y_pred = np.array(sample_preds['y_pred_voting'])
    
    if filter_option == "Correct Predictions":
        mask = y_true == y_pred
        df_filtered = df[mask]
    elif filter_option == "Incorrect Predictions":
        mask = y_true != y_pred
        df_filtered = df[mask]
    elif filter_option == "Attacks Only":
        mask = y_true == 1
        df_filtered = df[mask]
    elif filter_option == "Benign Only":
        mask = y_true == 0
        df_filtered = df[mask]
    else:
        df_filtered = df
    
    st.dataframe(df_filtered.head(n_rows), use_container_width=True)
    
    csv = df_filtered.to_csv(index=False).encode()
    st.download_button(
        "‚¨áÔ∏è Download Sample Predictions",
        csv,
        "sample_predictions.csv",
        "text/csv"
    )